{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling on abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, RegexpTokenizer,PunktSentenceTokenizer, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#abstracts = pd.read_csv(\"abstracts.csv\")\n",
    "abstracts = pd.read_csv(\"abstracts_eng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The goal of this note is to introduce new clas...</td>\n",
       "      <td>188444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>We will review a Lemma published by Ran Raz in...</td>\n",
       "      <td>188623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>China’s growing influence in Europe has the po...</td>\n",
       "      <td>346708.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Nowhere is China's Belt and Road Initiative (B...</td>\n",
       "      <td>346709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Passenger transit modes typical of the urban s...</td>\n",
       "      <td>187461.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract        id\n",
       "0  The goal of this note is to introduce new clas...  188444.0\n",
       "1  We will review a Lemma published by Ran Raz in...  188623.0\n",
       "2  China’s growing influence in Europe has the po...  346708.0\n",
       "3  Nowhere is China's Belt and Road Initiative (B...  346709.0\n",
       "4  Passenger transit modes typical of the urban s...  187461.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_list = list(abstracts['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20494"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21421** abstracts in total  \n",
    "**20494** abstracts in english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Step 1 \n",
    "- tokenization \n",
    "- punctuation removal \n",
    "- lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3855522 tokens created\n"
     ]
    }
   ],
   "source": [
    "tokenised = []\n",
    "count = 0\n",
    "for abstract in abs_list:\n",
    "    raw = abstract\n",
    "    tokens = gensim.utils.simple_preprocess(str(raw), deacc=True)\n",
    "    tokenised.append(tokens)\n",
    "    count += len(tokens)\n",
    "print(str(count)+\" tokens created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71429"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "for doc in tokenised: \n",
    "    c+=doc\n",
    "len(set(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have **83831** / **71429** (de/en) unique words in the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Step 2 \n",
    "- removing stopwords \n",
    "- (removing other words based on different strategies - like word length thresholding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "cleaned = [[word for word in doc if word not in stop_words] for doc in tokenised]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider extending the stopwords ...\n",
    "# stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider removing words with less than [x] characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71293"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "for doc in cleaned: \n",
    "    c+=doc\n",
    "len(set(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after stopwords removal we have **83695** / **71293** terms (136 less)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Step 3 \n",
    "- stemming \n",
    "- lemmatizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_stemmer = PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "lemmatized = [[lemmatiser.lemmatize(word_stemmer.stem(word)) for word in doc] for doc in cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71293"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "for doc in cleaned: \n",
    "    c+=doc\n",
    "len(set(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after stemming and lemmatization we have **61182** / **50948** terms (22,513 less)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daniel: slightly different approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_clean = []\n",
    "for i in range(len(lemmatized)):\n",
    "    b=(' '.join(word for word in lemmatized[i]))\n",
    "    abstract_clean.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'last two decad electr distribut sector wit wave regulatori reform aim improv effici incent regul regul scheme use benchmark name measur compani effici reward accordingli reliabl effici estim crucial effect implement incent mechan main problem face regul choic among sever legitim benchmark model usual produc differ result brief overview benchmark methodolog paper summar method use regul practic sever oecd countri benchmark practic rel widespread repeat observ similar compani time name panel data allow better understand unobserv firm specif factor disentangl effici estim focus parametr cost frontier model paper present two altern approach could use improv reliabl benchmark method base recent empir evid draw recommend regulatori practic power distribut network'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_clean[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Build n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be done before lemmatization and stemming in a lot of tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we could also lemmatise keeping only noun, adjective, verb, adverb\n",
    "\n",
    "data_lemmatized = lemmatization(bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-grams creationg parameters\n",
    "# min_count (float, optional) – Ignore all words and bigrams with total collected count lower than this value.\n",
    "# threshold (float, optional) – Represent a score threshold for forming the phrases (higher means fewer phrases)\n",
    "# scoring ({'default', 'npmi', function}, optional) –Specify how potential phrases are scored\n",
    "bigram = gensim.models.Phrases(lemmatized, min_count=5, threshold=50) \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two interesting results from the bigram model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1: no change --> no bigrams found \n",
    "lemmatized[0]==bigram_mod[lemmatized[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: some change but we actually lose vocabulary ...\n",
    "len(bigram_mod[lemmatized[110]])-len(lemmatized[110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edit', 'volum', 'inquir', 'use', 'predict', 'intersect', 'polit', 'academia', 'reflect', 'upon', 'implic', 'futur', 'orient', 'polici', 'make', 'across', 'differ', 'field', 'first', 'part', 'book', 'discus', 'differ', 'academ', 'perspect', 'contribut', 'futur', 'orient', 'polici', 'make', 'second', 'part', 'discus', 'role', 'futur', 'knowledg', 'decis_make', 'across', 'differ', 'empir', 'issu', 'climat', 'health', 'financ', 'bio', 'nuclear_weapon', 'civil_war', 'crime', 'analys', 'predict', 'integr', 'public', 'polici', 'govern', 'return', 'govern', 'structur', 'influenc', 'make', 'knowledg', 'futur', 'volum', 'contribut', 'better_understand', 'complex', 'interact', 'feedback_loop', 'process', 'creat', 'knowledg', 'futur', 'applic', 'futur', 'knowledg', 'public', 'polici', 'govern', 'publish', 'websit', 'dieser', 'sammelband', 'untersucht', 'den', 'einsatz', 'von', 'vorhersagen', 'der', 'schnittstel', 'zwischen', 'politik_und', 'wissenschaft', 'und', 'reflektiert', 'uber_die', 'auswirkungen', 'verschiedenen', 'bereichen', 'im_ersten', 'teil', 'de', 'buch', 'werden', 'verschieden', 'akademisch', 'perspektiven', 'und', 'beitrag', 'zur', 'diskutiert', 'im', 'zweiten', 'teil', 'wird_die', 'roll', 'zukunftigen', 'wissen', 'bei_der', 'verschiedenen', 'empirischen', 'bereichen', 'wie', 'klima', 'gesundheit', 'finanzen', 'bio', 'und', 'atomwaffen', 'burgerkrieg', 'und', 'kriminalitat', 'untersucht', 'e', 'wird', 'analysiert', 'wie', 'vorhersagen', 'die', 'offentlich', 'politik_und', 'integriert', 'werden', 'und', 'wie', 'wiederum', 'die', 'da', 'generieren', 'von', 'wissen', 'uber_die', 'zukunft', 'beeinflussen', 'der', 'sammelband', 'tragt', 'zu_einem', 'besseren', 'verstandni', 'der', 'komplexen', 'und', 'zwischen_den', 'prozessen', 'der', 'schaffung', 'von', 'wissen', 'uber_die', 'zukunft', 'und_der', 'anwendung', 'dy', 'wissen', 'politik_und', 'verwaltung', 'bei']\n"
     ]
    }
   ],
   "source": [
    "# MOREOVER, we have german words inside!!\n",
    "print(bigram_mod[lemmatized[110]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = gensim.models.Phrases(bigram[lemmatized], min_count=5, threshold=5)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relev', 'nuclear_weapon', 'world', 'affair', 'increa_decrea', 'nuclear_power', 'modern', 'arsen', 'may', 'result', 'destabil', 'effect', 'nuclear', 'deterr', 'constel', 'time', 'discrep', 'import', 'arm', 'control', 'necessari', 'supplement', 'nuclear', 'deterr', 'one_hand', 'actual', 'limit', 'role', 'intern', 'affair', 'hand', 'constantli', 'grow', 'order_avoid', 'futur', 'nuclear_war', 'creat', 'strateg', 'stabil', 'renaiss', 'arm', 'control', 'urgent_need']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at some of the trigrams\n",
    "print(trigram_mod[lemmatized[31]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrammed = make_bigrams(lemmatized)\n",
    "cleaned = make_trigrams(bigrammed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68689"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "for doc in cleaned: \n",
    "    c+=doc\n",
    "len(set(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After grouping words that occur commonly together we have / **68689** terms (17,741 more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Analyse the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = flatten(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', 11657),\n",
       " ('model', 10841),\n",
       " ('results', 9409),\n",
       " ('based', 9307),\n",
       " ('using', 8577),\n",
       " ('two', 7303),\n",
       " ('study', 7211),\n",
       " ('high', 7092),\n",
       " ('time', 7025),\n",
       " ('different', 6783)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(counts.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3.7 install tomotopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tomotopy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "tw = tp.TermWeight.ONE # term weighting scheme in TermWeight. The default value is TermWeight.ONE\n",
    "k = 30 # number of topics...\n",
    "min_cf=3 # minimum collection frequency of words. Words with a smaller collection frequency than min_cf are excluded from the model. The default value is 0, which means no words are excluded.\n",
    "min_df=0 # minimum document frequency of words. Words with a smaller document frequency than min_df are excluded from the model. The default value is 0, which means no words are excluded\n",
    "rm_top=5 # the number of top words to be removed. If you want to remove too common words from model, you can set this value to 1 or more. The default value is 0, which means no top words are removed.\n",
    "alpha = None # hyperparameter of Dirichlet distribution for document-topic\n",
    "eta = None # hyperparameter of Dirichlet distribution for topic-word\n",
    "seed = 41 # random seed\n",
    "model_burn_in = 100 \n",
    "train_updates = 1000\n",
    "train_iter = 10\n",
    "save_path = \"lda_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the model\n",
    "model = tp.LDAModel(tw=tp.TermWeight.ONE, min_cf=min_cf, rm_top=rm_top, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding documents to the model \n",
    "for doc in cleaned: model.add_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs: 20494 , Vocab size: 41921 , Num words: 2047104\n",
      "Removed top words: ['use', 'model', 'result', 'studi', 'base']\n",
      "Iteration: 0\n",
      "Iteration: 100\n",
      "Iteration: 200\n",
      "Iteration: 300\n",
      "Iteration: 400\n",
      "Iteration: 500\n",
      "Iteration: 600\n",
      "Iteration: 700\n",
      "Iteration: 800\n",
      "Iteration: 900\n"
     ]
    }
   ],
   "source": [
    "# training**\n",
    "model.burn_in = model_burn_in\n",
    "# initialising \n",
    "model.train(iter=0)\n",
    "print('Num docs:', len(model.docs), ', Vocab size:', len(model.used_vocabs), ', Num words:', model.num_words)\n",
    "print('Removed top words:', model.removed_top_words)\n",
    "print('Training...', file=sys.stderr, flush=True)\n",
    "# actual training \n",
    "time = []\n",
    "LLs = []\n",
    "for i in range(0, train_updates, train_iter):\n",
    "    model.train(train_iter)\n",
    "    if i%100==0:print('Iteration: {}'.format(i))\n",
    "    time.append(i)\n",
    "    LLs.append(model.ll_per_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iteration')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(time,LLs)\n",
    "plt.ylabel('Log-likelihood')\n",
    "plt.xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Basic Info>\n",
      "| LDAModel (current version: 0.9.1)\n",
      "| 20494 docs, 2047104 words\n",
      "| Total Vocabs: 68689, Used Vocabs: 41921\n",
      "| Entropy of words: -8.69615\n",
      "| Removed Vocabs: use model result studi base\n",
      "|\n",
      "<Training Info>\n",
      "| Iterations: 1000, Burn-in steps: 100\n",
      "| Optimization Interval: 10\n",
      "| Log-likelihood per word: -8.63168\n",
      "|\n",
      "<Initial Parameters>\n",
      "| tw: TermWeight.ONE\n",
      "| min_cf: 3 (minimum collection frequency of words)\n",
      "| min_df: 0 (minimum document frequency of words)\n",
      "| rm_top: 5 (the number of top words to be removed)\n",
      "| k: 30 (the number of topics between 1 ~ 32767)\n",
      "| alpha: 0.1 (hyperparameter of Dirichlet distribution for document-topic)\n",
      "| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)\n",
      "| seed: 413981393 (random seed)\n",
      "| trained in version 0.9.1\n",
      "|\n",
      "<Parameters>\n",
      "| alpha (Dirichlet prior on the per-document topic distributions)\n",
      "|  [0.02115543 0.04057477 0.0473648  0.03881337 0.03060828 0.03408973\n",
      "|   0.04750634 0.02920154 0.03210319 0.03348985 0.14166176 0.02239393\n",
      "|   0.02050162 0.34959254 0.01789482 0.00670509 0.02380325 0.02882896\n",
      "|   0.03361249 0.05521702 0.02625764 0.04729076 0.01606809 0.05106092\n",
      "|   0.03988693 0.01632953 0.01218499 0.02354932 0.05027501 0.1976262 ]\n",
      "| eta (Dirichlet prior on the per-topic word distribution)\n",
      "|  0.01\n",
      "|\n",
      "<Topics>\n",
      "| #0 (30640) : survey activ data particip choic\n",
      "| #1 (58831) : countri polici effect firm product\n",
      "| #2 (70662) : reaction oxid activ water surfac\n",
      "| #3 (53094) : system optim energi design product\n",
      "| #4 (39046) : social group work relat student\n",
      "| #5 (62621) : chang climat region temperatur simul\n",
      "| #6 (69961) : electron magnet measur optic field\n",
      "| #7 (58081) : soil plant speci forest increa\n",
      "| #8 (64799) : gene speci popul genom sequenc\n",
      "| #9 (48734) : algorithm network problem graph show\n",
      "| #10 (149690) : develop research data system process\n",
      "| #11 (48981) : neuron brain activ function connect\n",
      "| #12 (45987) : emiss observ measur co ozon\n",
      "| #13 (280123) : differ effect chang observ howev\n",
      "| #14 (31187) : measur jet present data particl\n",
      "| #15 (13648) : der und die von de\n",
      "| #16 (44626) : bacteria strain bacteri product infect\n",
      "| #17 (38404) : imag seismic map earthquak measur\n",
      "| #18 (75413) : patient as measur group method\n",
      "| #19 (72355) : gener function theori problem approxim\n",
      "| #20 (54735) : sediment water lake river age\n",
      "| #21 (59434) : system control perform sensor design\n",
      "| #22 (35950) : search mass product event standard_model\n",
      "| #23 (70213) : materi structur flow mechan surfac\n",
      "| #24 (88276) : cell express activ induc human\n",
      "| #25 (36433) : particl aerosol cloud measur observ\n",
      "| #26 (17242) : mass observ galaxi detect imag\n",
      "| #27 (35137) : network urban simul citi traffic\n",
      "| #28 (97113) : protein function cell activ complex\n",
      "| #29 (195688) : method data approach measur estim\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    }
   ],
   "source": [
    "print('Saving...', file=sys.stderr, flush=True)\n",
    "model.save(save_path, full=True) # If full is True, the model with its all documents and state will be saved. If you want to train more after, use full model. If False, only topic parameters of the model will be saved. This model can be only used for inference of an unseen document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a better look at the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0\n",
      "\t\tsurvey\t0.013973632827401161\n",
      "\t\tactiv\t0.012106232345104218\n",
      "\t\tdata\t0.011494496837258339\n",
      "\t\tparticip\t0.009594899602234364\n",
      "\t\tchoic\t0.009111951105296612\n",
      "\t\ttime\t0.008822182193398476\n",
      "\t\tperson\t0.007405532523989677\n",
      "\t\thousehold\t0.007180156651884317\n",
      "\t\tbehavior\t0.007147959899157286\n",
      "\t\testim\t0.007147959899157286\n",
      "Topic #1\n",
      "\t\tcountri\t0.01404231321066618\n",
      "\t\tpolici\t0.012152024544775486\n",
      "\t\teffect\t0.011071859858930111\n",
      "\t\tfirm\t0.008573978208005428\n",
      "\t\tproduct\t0.008523344993591309\n",
      "\t\tfind\t0.008287059143185616\n",
      "\t\tmarket\t0.007881997153162956\n",
      "\t\tprice\t0.007240649312734604\n",
      "\t\teconom\t0.006886220537126064\n",
      "\t\tincrea\t0.006126729305833578\n",
      "Topic #2\n",
      "\t\treaction\t0.008497463539242744\n",
      "\t\toxid\t0.00690773269161582\n",
      "\t\tactiv\t0.006767048500478268\n",
      "\t\twater\t0.005782259628176689\n",
      "\t\tsurfac\t0.0055853016674518585\n",
      "\t\tformat\t0.005543096456676722\n",
      "\t\tchemic\t0.005332070402801037\n",
      "\t\tconcentr\t0.005303933285176754\n",
      "\t\tco\t0.005135112442076206\n",
      "\t\tprocess\t0.00483967550098896\n",
      "Topic #3\n",
      "\t\tsystem\t0.01928514428436756\n",
      "\t\toptim\t0.016986647620797157\n",
      "\t\tenergi\t0.015921488404273987\n",
      "\t\tdesign\t0.014090165495872498\n",
      "\t\tproduct\t0.01171691995114088\n",
      "\t\tprocess\t0.011530050076544285\n",
      "\t\toper\t0.010894693434238434\n",
      "\t\tcost\t0.009194178506731987\n",
      "\t\teffici\t0.008129021152853966\n",
      "\t\treduc\t0.007587098516523838\n",
      "Topic #4\n",
      "\t\tsocial\t0.011352024041116238\n",
      "\t\tgroup\t0.008640775457024574\n",
      "\t\twork\t0.008463403210043907\n",
      "\t\trelat\t0.0070190937258303165\n",
      "\t\tstudent\t0.006993754766881466\n",
      "\t\tarchitectur\t0.005574783310294151\n",
      "\t\tcooper\t0.005524105858057737\n",
      "\t\tlearn\t0.005296056624501944\n",
      "\t\tdesign\t0.005194701720029116\n",
      "\t\tconcept\t0.004865297582000494\n",
      "Topic #5\n",
      "\t\tchang\t0.01261115726083517\n",
      "\t\tclimat\t0.012230447493493557\n",
      "\t\tregion\t0.011421440169215202\n",
      "\t\ttemperatur\t0.011246948502957821\n",
      "\t\tsimul\t0.009803425520658493\n",
      "\t\tobserv\t0.008677160367369652\n",
      "\t\tincrea\t0.008328177034854889\n",
      "\t\tprecipit\t0.006662573199719191\n",
      "\t\twater\t0.006646709982305765\n",
      "\t\timpact\t0.006028057541698217\n",
      "Topic #6\n",
      "\t\telectron\t0.008482640609145164\n",
      "\t\tmagnet\t0.008127426728606224\n",
      "\t\tmeasur\t0.008127426728606224\n",
      "\t\toptic\t0.006365567911416292\n",
      "\t\tfield\t0.006266108248382807\n",
      "\t\tsystem\t0.006223482545465231\n",
      "\t\treson\t0.005726183764636517\n",
      "\t\tmateri\t0.005726183764636517\n",
      "\t\texperi\t0.005726183764636517\n",
      "\t\tdevic\t0.005655141081660986\n",
      "Topic #7\n",
      "\t\tsoil\t0.019025743007659912\n",
      "\t\tplant\t0.01878642849624157\n",
      "\t\tspeci\t0.014205248095095158\n",
      "\t\tforest\t0.010871926322579384\n",
      "\t\tincrea\t0.008615524508059025\n",
      "\t\teffect\t0.007162538357079029\n",
      "\t\tproduct\t0.006222371011972427\n",
      "\t\troot\t0.006205277051776648\n",
      "\t\tcrop\t0.006102713290601969\n",
      "\t\tdiffer\t0.005743740126490593\n",
      "Topic #8\n",
      "\t\tgene\t0.01599261909723282\n",
      "\t\tspeci\t0.014167975634336472\n",
      "\t\tpopul\t0.013109988532960415\n",
      "\t\tgenom\t0.012695994228124619\n",
      "\t\tsequenc\t0.00946070160716772\n",
      "\t\tinfect\t0.008080719038844109\n",
      "\t\tgenet\t0.007513392250984907\n",
      "\t\thost\t0.00673140212893486\n",
      "\t\tselect\t0.006225408520549536\n",
      "\t\tassoci\t0.006010744720697403\n",
      "Topic #9\n",
      "\t\talgorithm\t0.013020716607570648\n",
      "\t\tnetwork\t0.012980027124285698\n",
      "\t\tproblem\t0.012288312427699566\n",
      "\t\tgraph\t0.010050411336123943\n",
      "\t\tshow\t0.00876870471984148\n",
      "\t\tset\t0.008015956729650497\n",
      "\t\tnode\t0.006978384684771299\n",
      "\t\tcomput\t0.00632735900580883\n",
      "\t\tprotocol\t0.006144258193671703\n",
      "\t\tsecur\t0.005859434138983488\n",
      "Topic #10\n",
      "\t\tdevelop\t0.013643467798829079\n",
      "\t\tresearch\t0.010259264148771763\n",
      "\t\tdata\t0.008493882603943348\n",
      "\t\tsystem\t0.008453912101686\n",
      "\t\tprocess\t0.006888385396450758\n",
      "\t\tinform\t0.0065286471508443356\n",
      "\t\tprovid\t0.0062421890906989574\n",
      "\t\tapproach\t0.006075643468648195\n",
      "\t\ttechnolog\t0.005822494626045227\n",
      "\t\tinclud\t0.005742552690207958\n",
      "Topic #11\n",
      "\t\tneuron\t0.013299740850925446\n",
      "\t\tbrain\t0.011801771819591522\n",
      "\t\tactiv\t0.008886804804205894\n",
      "\t\tfunction\t0.007125678472220898\n",
      "\t\tconnect\t0.006376693490892649\n",
      "\t\ttask\t0.006376693490892649\n",
      "\t\trelat\t0.005708680488169193\n",
      "\t\tbehavior\t0.005688437260687351\n",
      "\t\tcontrol\t0.005627708975225687\n",
      "\t\tassoci\t0.0055872234515845776\n",
      "Topic #12\n",
      "\t\temiss\t0.014782719314098358\n",
      "\t\tobserv\t0.012649384327232838\n",
      "\t\tmeasur\t0.010709988884627819\n",
      "\t\tco\t0.010494500398635864\n",
      "\t\tozon\t0.008490458130836487\n",
      "\t\tatmosph\t0.008188774809241295\n",
      "\t\tsimul\t0.007951737381517887\n",
      "\t\tregion\t0.007046686485409737\n",
      "\t\tflux\t0.006917393300682306\n",
      "\t\tchang\t0.006895844358950853\n",
      "Topic #13\n",
      "\t\tdiffer\t0.013238685205578804\n",
      "\t\teffect\t0.010921742767095566\n",
      "\t\tchang\t0.009128786623477936\n",
      "\t\tobserv\t0.0077778310514986515\n",
      "\t\thowev\t0.006615795660763979\n",
      "\t\tincrea\t0.006533811800181866\n",
      "\t\tshow\t0.006412617862224579\n",
      "\t\tdynam\t0.006391230504959822\n",
      "\t\ttime\t0.005992003716528416\n",
      "\t\texperi\t0.0058957613073289394\n",
      "Topic #14\n",
      "\t\tmeasur\t0.035562947392463684\n",
      "\t\tjet\t0.011010810732841492\n",
      "\t\tpresent\t0.010694417171180248\n",
      "\t\tdata\t0.009049170650541782\n",
      "\t\tparticl\t0.008669499307870865\n",
      "\t\tcross_section\t0.008637859486043453\n",
      "\t\tevent\t0.008353105746209621\n",
      "\t\tgev\t0.008131629787385464\n",
      "\t\tfunction\t0.008099990896880627\n",
      "\t\tcompar\t0.008005072362720966\n",
      "Topic #15\n",
      "\t\tder\t0.036255236715078354\n",
      "\t\tund\t0.03270087018609047\n",
      "\t\tdie\t0.031065862625837326\n",
      "\t\tvon\t0.014929044060409069\n",
      "\t\tde\t0.014573607593774796\n",
      "\t\tein\t0.012085551396012306\n",
      "\t\tda\t0.010592718608677387\n",
      "\t\tzu\t0.010450543835759163\n",
      "\t\tim\t0.009028797969222069\n",
      "\t\tmit\t0.008389012888073921\n",
      "Topic #16\n",
      "\t\tbacteria\t0.012032577767968178\n",
      "\t\tstrain\t0.009945785626769066\n",
      "\t\tbacteri\t0.008169792592525482\n",
      "\t\tproduct\t0.006882196757942438\n",
      "\t\tinfect\t0.006704597733914852\n",
      "\t\tconcentr\t0.005949800368398428\n",
      "\t\tisol\t0.005927600432187319\n",
      "\t\tcell\t0.005727801006287336\n",
      "\t\tiron\t0.005705601070076227\n",
      "\t\tresist\t0.0056168013252317905\n",
      "Topic #17\n",
      "\t\timag\t0.02931261993944645\n",
      "\t\tseismic\t0.010663981549441814\n",
      "\t\tmap\t0.00891245249658823\n",
      "\t\tearthquak\t0.008242749609053135\n",
      "\t\tmeasur\t0.007624562829732895\n",
      "\t\tarea\t0.006594251375645399\n",
      "\t\tveloc\t0.006491219624876976\n",
      "\t\treconstruct\t0.005873032845556736\n",
      "\t\tdetect\t0.005847275257110596\n",
      "\t\tfault\t0.005641212686896324\n",
      "Topic #18\n",
      "\t\tpatient\t0.01943778246641159\n",
      "\t\tas\t0.010009071789681911\n",
      "\t\tmeasur\t0.009006858803331852\n",
      "\t\tgroup\t0.008189263753592968\n",
      "\t\tmethod\t0.007187051698565483\n",
      "\t\tcompar\t0.006831002421677113\n",
      "\t\tconclu\t0.006712319329380989\n",
      "\t\tperform\t0.0064353919588029385\n",
      "\t\ttest\t0.006079342681914568\n",
      "\t\tinterv\t0.005696919746696949\n",
      "Topic #19\n",
      "\t\tgener\t0.010388433001935482\n",
      "\t\tfunction\t0.008602085523307323\n",
      "\t\ttheori\t0.008189852349460125\n",
      "\t\tproblem\t0.007818841375410557\n",
      "\t\tapproxim\t0.007434089668095112\n",
      "\t\tsolut\t0.007406607270240784\n",
      "\t\tshow\t0.006911926902830601\n",
      "\t\tsystem\t0.00669206865131855\n",
      "\t\tcomput\t0.006293575745075941\n",
      "\t\tderiv\t0.005840118508785963\n",
      "Topic #20\n",
      "\t\tsediment\t0.009518946520984173\n",
      "\t\twater\t0.007760241627693176\n",
      "\t\tlake\t0.006364156026393175\n",
      "\t\triver\t0.0058383578434586525\n",
      "\t\tage\t0.00547573808580637\n",
      "\t\tisotop\t0.005004332400858402\n",
      "\t\tsampl\t0.004859284497797489\n",
      "\t\tcarbon\t0.004406009800732136\n",
      "\t\tsuggest\t0.004351616837084293\n",
      "\t\trecord\t0.004170306958258152\n",
      "Topic #21\n",
      "\t\tsystem\t0.021953877061605453\n",
      "\t\tcontrol\t0.011845814064145088\n",
      "\t\tperform\t0.010776531882584095\n",
      "\t\tsensor\t0.009690540842711926\n",
      "\t\tdesign\t0.008938701823353767\n",
      "\t\ttrain\t0.008270400576293468\n",
      "\t\trobot\t0.007602098397910595\n",
      "\t\ttask\t0.007084164768457413\n",
      "\t\tlearn\t0.006833551451563835\n",
      "\t\tdevic\t0.006733306217938662\n",
      "Topic #22\n",
      "\t\tsearch\t0.013253243640065193\n",
      "\t\tmass\t0.012675832025706768\n",
      "\t\tproduct\t0.012153412215411663\n",
      "\t\tevent\t0.011988437734544277\n",
      "\t\tstandard_model\t0.01196094136685133\n",
      "\t\tobserv\t0.009348842315375805\n",
      "\t\tlimit\t0.009266355074942112\n",
      "\t\tcorrespond_integr_lumino_fb\t0.008166523650288582\n",
      "\t\tdecay\t0.007369145750999451\n",
      "\t\tfinal_state\t0.006874220911413431\n",
      "Topic #23\n",
      "\t\tmateri\t0.012699729762971401\n",
      "\t\tstructur\t0.012614782899618149\n",
      "\t\tflow\t0.009032847359776497\n",
      "\t\tmechan\t0.009004532359540462\n",
      "\t\tsurfac\t0.008240008726716042\n",
      "\t\texperi\t0.006994117982685566\n",
      "\t\ttest\t0.0066118561662733555\n",
      "\t\tmeasur\t0.005776543170213699\n",
      "\t\tdeform\t0.005465070251375437\n",
      "\t\tload\t0.005238545127213001\n",
      "Topic #24\n",
      "\t\tcell\t0.02360905334353447\n",
      "\t\texpress\t0.008185448125004768\n",
      "\t\tactiv\t0.007835935801267624\n",
      "\t\tinduc\t0.007159462198615074\n",
      "\t\thuman\t0.0066972048953175545\n",
      "\t\ttissu\t0.006573184859007597\n",
      "\t\tmous\t0.006156025920063257\n",
      "\t\tincrea\t0.005208962131291628\n",
      "\t\ttreatment\t0.005073667503893375\n",
      "\t\tdevelop\t0.004825626965612173\n",
      "Topic #25\n",
      "\t\tparticl\t0.022604070603847504\n",
      "\t\taerosol\t0.018180999904870987\n",
      "\t\tcloud\t0.016471467912197113\n",
      "\t\tmeasur\t0.01565740630030632\n",
      "\t\tobserv\t0.009226311929523945\n",
      "\t\tconcentr\t0.008819281123578548\n",
      "\t\tsimul\t0.0070283436216413975\n",
      "\t\tatmosph\t0.006811260245740414\n",
      "\t\ttemperatur\t0.006322822533547878\n",
      "\t\twater\t0.00602433318272233\n",
      "Topic #26\n",
      "\t\tmass\t0.013249940238893032\n",
      "\t\tobserv\t0.013023455627262592\n",
      "\t\tgalaxi\t0.01155130285769701\n",
      "\t\tdetect\t0.008267269469797611\n",
      "\t\timag\t0.006738496012985706\n",
      "\t\torbit\t0.006172283552587032\n",
      "\t\tdisk\t0.006002419628202915\n",
      "\t\tstar\t0.005662692245095968\n",
      "\t\tplanet\t0.005322964861989021\n",
      "\t\tgroup\t0.005322964861989021\n",
      "Topic #27\n",
      "\t\tnetwork\t0.016762472689151764\n",
      "\t\turban\t0.015496870502829552\n",
      "\t\tsimul\t0.01515937689691782\n",
      "\t\tciti\t0.013162539340555668\n",
      "\t\ttraffic\t0.00987197458744049\n",
      "\t\tvehicl\t0.009646979160606861\n",
      "\t\tarea\t0.007593891583383083\n",
      "\t\tdemand\t0.007537642493844032\n",
      "\t\ttransport\t0.007481393404304981\n",
      "\t\tplan\t0.0074251447804272175\n",
      "Topic #28\n",
      "\t\tprotein\t0.021623728796839714\n",
      "\t\tfunction\t0.01056071650236845\n",
      "\t\tcell\t0.010345403105020523\n",
      "\t\tactiv\t0.008899726904928684\n",
      "\t\tcomplex\t0.007577086798846722\n",
      "\t\tregul\t0.007402785122394562\n",
      "\t\tinteract\t0.006387735716998577\n",
      "\t\tgene\t0.006254446692764759\n",
      "\t\tstructur\t0.006018626969307661\n",
      "\t\texpress\t0.00585457868874073\n",
      "Topic #29\n",
      "\t\tmethod\t0.02197272516787052\n",
      "\t\tdata\t0.02088148705661297\n",
      "\t\tapproach\t0.01326320506632328\n",
      "\t\tmeasur\t0.01066258642822504\n",
      "\t\testim\t0.00933168176561594\n",
      "\t\tperform\t0.009010428562760353\n",
      "\t\tanalysi\t0.00850050337612629\n",
      "\t\tpredict\t0.00819964800029993\n",
      "\t\tsampl\t0.007949784398078918\n",
      "\t\tdiffer\t0.007597936317324638\n"
     ]
    }
   ],
   "source": [
    "for k in range(model.k):\n",
    "    print('Topic #{}'.format(k))\n",
    "    for word, prob in model.get_topic_words(k):\n",
    "        print('\\t', word, prob, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning by optimizing log-likelihood  \n",
    "Note: log-likelihood is generally not considered a good measure for topic model performance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LDA(documents, k, min_cf=0, min_df=0, rm_top=0, alpha=0.1, eta=0.01, model_burn_in=100, \n",
    "              train_updates = 1000, train_iter = 10):\n",
    "    \n",
    "    # instantiate\n",
    "    model = tp.LDAModel(tw=tp.TermWeight.ONE, min_cf=min_cf, rm_top=rm_top, k=k)\n",
    "    \n",
    "    # add documents to model\n",
    "    for doc in documents: model.add_doc(doc)\n",
    "    \n",
    "    # training**\n",
    "    model.burn_in = model_burn_in\n",
    "    # initialising \n",
    "    model.train(iter=0)\n",
    "    print('Num docs:', len(model.docs), ', Vocab size:', len(model.used_vocabs), ', Num words:', model.num_words)\n",
    "    print('Removed top words:', model.removed_top_words)\n",
    "    print('Training...', file=sys.stderr, flush=True)\n",
    "    # actual training \n",
    "    time = []\n",
    "    LLs = []\n",
    "    for i in range(0, train_updates, train_iter):\n",
    "        model.train(train_iter)\n",
    "        if i%100==0:print('Iteration: {}'.format(i))\n",
    "        time.append(i)\n",
    "        LLs.append(model.ll_per_word)\n",
    "    \n",
    "    return model, LLs, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple loop for minimizing perplexity on the training set\n",
    "\n",
    "topics = [10,20,30]\n",
    "perplexity_score = np.array([])\n",
    "for k in topics:\n",
    "    model, LLs, time = train_LDA(cleaned, k = k, train_updates = 600)\n",
    "    perplexity_score = np.append(perplexity_score, model.perplexity)\n",
    "\n",
    "topics[np.argmin(perplexity_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20494\n"
     ]
    }
   ],
   "source": [
    "# split data in train and test set\n",
    "\n",
    "print(len(cleaned))\n",
    "train_size = int(0.8*len(cleaned))\n",
    "\n",
    "random.shuffle(cleaned)\n",
    "train_docs = cleaned[0:train_size]\n",
    "test_docs = cleaned[train_size:]\n",
    "\n",
    "assert len(train_docs) + len(test_docs) == len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_LL(test_docs, model):\n",
    "    \n",
    "    # make a list of documents of type required by tp\n",
    "    test_set = []\n",
    "    for doc in test_docs:\n",
    "        test_set.append(model.make_doc(doc))\n",
    "    \n",
    "    # return topic distribution and log-likelihood of new documents\n",
    "    topic_dist, likelihood = model.infer(test_set)\n",
    "    \n",
    "    # use mean log-likelihood as performance measure\n",
    "    return np.mean(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs: 16395 , Vocab size: 62919 , Num words: 1713454\n",
      "Removed top words: []\n",
      "Iteration: 0\n",
      "Iteration: 100\n",
      "Iteration: 200\n",
      "Iteration: 300\n",
      "Iteration: 400\n",
      "Iteration: 500\n",
      "Iteration: 600\n",
      "Iteration: 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs: 16395 , Vocab size: 62919 , Num words: 1713454\n",
      "Removed top words: []\n",
      "Iteration: 0\n",
      "Iteration: 100\n",
      "Iteration: 200\n",
      "Iteration: 300\n",
      "Iteration: 400\n",
      "Iteration: 500\n",
      "Iteration: 600\n",
      "Iteration: 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num docs: 16395 , Vocab size: 62919 , Num words: 1713454\n",
      "Removed top words: []\n",
      "Iteration: 0\n",
      "Iteration: 100\n",
      "Iteration: 200\n",
      "Iteration: 300\n",
      "Iteration: 400\n",
      "Iteration: 500\n",
      "Iteration: 600\n",
      "Iteration: 700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop for maximizing mean likelihood of test set\n",
    "\n",
    "topics = [10,20,30]\n",
    "log_likelihoods = np.array([])\n",
    "for k in topics:\n",
    "    model, LLs, time = train_LDA(train_docs, k = k, train_updates = 800)\n",
    "    log_likelihoods = np.append(log_likelihoods, get_test_LL(test_docs, model))\n",
    "\n",
    "topics[np.argmax(log_likelihoods)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-882.05810779 -882.89588814 -879.71187388]\n"
     ]
    }
   ],
   "source": [
    "print(likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use new quality measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next up\n",
    "\n",
    "- experimenting with bigrams/trigrams\n",
    "- more solid results on LDA (with other measures and grid-search) \n",
    "- experimenting with CTM\n",
    "- experimenting with Pachinko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
