{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to explore the content of the listed below files, **identifying in which input fields the useful information lies, pinpointing the connections btw the files, and to merge all the data into a structure** which is ready to be fed into the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Available data - files\n",
    "files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "for f in files: print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResearchCollectionPublications2008_2018.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rcp = pd.read_csv(\"ResearchCollectionPublications2008_2018.tsv\", sep=\"\\t\", header=0, encoding=\"latin-1\") #utf8 not working..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_tf= rcp.loc[(rcp[\"DC_TYPE\"] == \"Journal Article\")|(rcp[\"DC_TYPE\"] == \"Conference Paper\")|\n",
    "        (rcp[\"DC_TYPE\"] ==\"Other Conference Item\")|\n",
    "        (rcp[\"DC_TYPE\"] ==\"Book Chapter\"),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we also need to convert types?\n",
    "rcp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_tf[\"DC_DATE_ISSUED\"].str.match(pat=\".*\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#force types on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(rcp[\"ETHZ_JOURNAL_TITLE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = rcp_tf.loc[(rcp_tf[\"DC_TYPE\"]==\"Journal Article\"),:].groupby(\"ETHZ_JOURNAL_TITLE\")[\"RC_ID\"].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_tf.groupby(\"ETHZ_PUBLICATION_PLACE\")[\"RC_ID\",\"ETHZ_JOURNAL_TITLE\"].count().sort_values(by=\"RC_ID\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_ff.loc[(rcp_ff[\"DC_DATE_ISSUED\"].str.match(pat=\"^[0-9]{4}$\")==True),:][\"DC_DATE_ISSUED\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nulls for columns\n",
    "rcp.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning \n",
    "\n",
    "**What information should be extracted?**\n",
    "\n",
    "- authors names from \"DC_CONTRIBUTOR_AUTHOR\"\n",
    "- editors names from \"DC_CONTRIBUTOR_EDITOR\" (ideally same function used for the above step) \n",
    "- date from \"DC_DATE_ISSUED\"\n",
    "- title from \"DC_TITLE\"\n",
    "- type of publication : Journal Article, Conference Paper, Other Conference Item,Book Chapter\n",
    "- journal of publication from ETHZ_JOURNAL_TITLE (filtered)\n",
    "- publication database from \"ETHZ_IDENTIFIER_ARXIV\" and similar\n",
    "\n",
    "\n",
    "- ...\n",
    "\n",
    "**Doubts/Observations**\n",
    "- (Should be tested) Author field is Nan AND Collection field is filled - what does this represent? \n",
    "- Conference Poster may not have abstracts\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "-  'Journal Article' with \n",
    "-  'Journal Article' and conference papers \n",
    "-  Threshold filtering of journal titles\n",
    "\n",
    "Postprocessing:\n",
    "- convert date issued to single format (year) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_ff = rcp_tf[[\"RC_ID\",\"DC_CONTRIBUTOR_AUTHOR\",\"DC_DATE_ISSUED\",\"DC_TITLE\",\"DC_TYPE\",\"ETHZ_JOURNAL_TITLE\"]]\n",
    "rcp_ff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning utils \n",
    "Here the code to clean this mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_names(names):\n",
    "    \"\"\" Separes a string of names of the form name1||name2||name3||... into a list of names.\"\"\"\n",
    "    # Also: does pandas DataFrame support list of strings as fields? \n",
    "    # Andreas: Yes\n",
    "    if isinstance(names, str):\n",
    "        return names.split(\"||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name fields to lists\n",
    "\n",
    "author_array = rcp.loc[:,\"DC_CONTRIBUTOR_AUTHOR\"].apply(separate_names)\n",
    "print(\"Check that we don't have more missing values: \", author_array.shape[0] - np.count_nonzero(author_array))\n",
    "editor_array = rcp.loc[:,\"DC_CONTRIBUTOR_EDITOR\"].apply(separate_names)\n",
    "print(\"Check that we don't have more missing values: \", editor_array.shape[0] - np.count_nonzero(editor_array))\n",
    "rcp[\"DC_CONTRIBUTOR_AUTHOR\"] = author_array\n",
    "rcp[\"DC_CONTRIBUTOR_EDITOR\"] = editor_array\n",
    "rcp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "author_array = rcp_ff.loc[:,\"DC_CONTRIBUTOR_AUTHOR\"].apply(separate_names)\n",
    "rcp_ff[\"DC_CONTRIBUTOR_AUTHOR\"] = author_array\n",
    "rcp_ff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(date):\n",
    "    \"Get the dates into a single format (YYYY)\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_ff_e = rcp_ff.explode(\"DC_CONTRIBUTOR_AUTHOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_ff_e.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-ARCH.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary requirement for xlsx files \n",
    "!python3 -m pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_excel(\"D-ARCH.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.iloc[0][\"RESEARCH_OVERVIEW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls for columns\n",
    "da.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file should be connected to the main one (Research Collection) through the professor name.<br>\n",
    "Integrates research overview info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the professors' names here and the authors' names there match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETH Professor list.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pd.read_excel(\"ETH Professor list.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls for columns\n",
    "pl.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this file matches the research collection through the professors' name. <br>\n",
    "Integrates organisation info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl[\"Professor\"] = pl[\"Name\"] + \", \" + pl[\"First name\"]\n",
    "pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a few examples\n",
    "\n",
    "#pl.loc[(pl[\"Professor\"]==\"Renner, Renato\"),:] # matches with rcp\n",
    "#pl.loc[(pl[\"Professor\"]==\"Diekmann, Andreas\"),:]\n",
    "#pl.loc[(pl[\"Name\"]==\"Diekmann\"),:] # this guy is an ETH professor but is missing in pl\n",
    "#pl.loc[(pl[\"Professor\"]==\"Mateo, Josep L.\"),:] \n",
    "#pl.loc[(pl[\"Name\"]==\"Mateo\"),:]  # same with this guy\n",
    "#pl.loc[(pl[\"Professor\"]==\"Wenger, Andreas\"),:] # matches with rcp\n",
    "#pl.loc[(pl[\"Professor\"]==\"Krause, Andreas\"),:] # CS represent\n",
    "pl.loc[(pl[\"Professor\"]==\"Buhmann, Joachim M.\"),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Organisation data is not homogeneous. Example: Krause is IML and Hofmann is dept. CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp.rename(columns={\"ETHZ_LEITZAHLIDENTIFIERS_CERT\":\"Org. unit code\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp[\"Org. unit code\"].str.match(pat=\"^[0-9]{5}$\")==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp[\"Org. unit code\"] = rcp.loc[(rcp[\"Org. unit code\"].str.match(pat=\"^[0-9]{5}$\")==True),\"Org. unit code\"].apply(lambda n: int(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_pl = pd.merge(pl, rcp, on='Org. unit code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_pl.loc[(rcp_pl[\"Organisation\"]==\"Institute for Machine Learning\"),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging rcp and pl on professors' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering pl\n",
    "pl_f = pl[[\"Organisation\",\"Professor\",\"Org. unit code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_m = pl_f.merge(rcp_ff_e,how=\"outer\",left_on=\"Professor\",right_on=\"DC_CONTRIBUTOR_AUTHOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rc_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_m_count = pd.DataFrame(rc_m[['ETHZ_JOURNAL_TITLE', 'DC_TITLE', 'DC_CONTRIBUTOR_AUTHOR']].groupby('ETHZ_JOURNAL_TITLE').count())\n",
    "rc_m_df = rc_m_count.reset_index()\n",
    "rc_m_reduced = rc_m_df.loc[rc_m_df['DC_TITLE'] > 100,:]\n",
    "print(rc_m_reduced.head())\n",
    "print('number of rows with publication in journals with more than 100 ETH entries:',len(rc_m_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_m_reduced.to_csv('publications.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find a way to import into neo4j (probably dumping into json -> organising into a dictionary)\n",
    "- visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation - not super useful right now but could be useful if we narrow down on area of research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rc_m.info() # 47626 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check number of unique journals\n",
    "len(rc_m.ETHZ_JOURNAL_TITLE.unique()) # 11881 unique journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rc_mp = rc_m[rc_m.groupby('ETHZ_JOURNAL_TITLE').ETHZ_JOURNAL_TITLE.transform('count')>100].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(rc_mp.groupby(\"ETHZ_JOURNAL_TITLE\")[\"RC_ID\"].count().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_mp.groupby(\"ETHZ_JOURNAL_TITLE\")[\"RC_ID\"].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResearchCollection.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = pd.read_excel(\"ResearchCollection.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls for columns\n",
    "rc.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Journal papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp = pd.read_csv(\"journal-2020-10-12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp.shape\n",
    "#pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jp.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jp[\"dc.description.abstract\"].notnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp[jp[\"dc.description.abstract\"].notnull()][\"dc.description.abstract\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring sub-selection options\n",
    "\n",
    "#### This is code that is dumped from Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_m.groupby(\"department_name\").size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlexdep = pd.DataFrame(rc_m[[\"department_code\",\"title\"]].groupby(\"title\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlexdep= titlexdep.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlexdep.columns = [\"title\",\"num_dept\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = titlexdep.merge(rc_m,how=\"right\",left_on=\"title\",right_on=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[[\"department_name\",\"num_dept\"]].groupby(\"department_name\").mean().sort_values(by=\"num_dept\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_m.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file matches the D-ARCH file through the departments' name. <br>\n",
    "Integrates departments info and websites links.\n",
    "\n",
    "Andreas: Is this data needed at this point?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Creating a final structure\n",
    "\n",
    "(In my opinion) the best final data structure is a dictionary (aka a tree) - can be dumped into a json file - which is easy to load into a neo4j graph. <br>\n",
    "In this section all the code to save the selected and integrated data into a dictionary.\n",
    "\n",
    "Andreas: Yes good idea. But we could also just directly dump a dataframe into a json right? Since pandas supports nested structures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Write a function that joins authors in rcp with professors in pl\n",
    "* Select relevant fields in first stage of the graph building and put in dataframe or dictionary\n",
    "* Export as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research-data-2020-10-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_csv(\"research-data-2020-10-12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(papers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = pd.DataFrame(papers[\"dc.description.abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = abstracts.drop(\"index\", axis=1)\n",
    "abstracts.columns = [\"text\"]\n",
    "abstracts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = pd.read_csv(\"educational-2020-10-12.csv\")\n",
    "books = pd.read_csv(\"books-2020-10-12.csv\")\n",
    "conf = pd.read_csv(\"conference-2020-10-12.csv\")\n",
    "journ = pd.read_csv(\"journal-2020-10-12.csv\")\n",
    "oth = pd.read_csv(\"other-2020-10-12.csv\")\n",
    "pap = pd.read_csv(\"papers-2020-10-12.csv\")\n",
    "pat = pd.read_csv(\"patents-2020-10-12.csv\")\n",
    "pres = pd.read_csv(\"presentations-2020-10-12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_data = [ed,books,conf,journ,oth,pap,pat,pres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "for df in research_data:\n",
    "    tot+=df.shape[0]\n",
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null = 0\n",
    "for df in research_data:\n",
    "    non_null+=sum(df[\"dc.description.abstract\"].notnull())\n",
    "non_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_all = []\n",
    "for df in research_data:\n",
    "    nn=sum(df[\"dc.description.abstract\"].notnull())\n",
    "    non_null_all+=[nn]\n",
    "non_null_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_len = []\n",
    "for df in research_data:\n",
    "    avg = np.mean((df.loc[df['dc.description.abstract'].notnull(),'dc.description.abstract']\n",
    "                   .apply(lambda x: len(x.split(\" \")))\n",
    "                   .reset_index(name='len_text'))[\"len_text\"])\n",
    "    avg_len+=[avg]\n",
    "avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
