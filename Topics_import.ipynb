{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import nltk\n",
    "from nltk import word_tokenize, RegexpTokenizer,PunktSentenceTokenizer, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the model and the abstracts file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tp.LDAModel.load(\"lda_model150.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"abstracts_eng.csv\")\n",
    "collection = list(data['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The goal of this note is to introduce new clas...</td>\n",
       "      <td>188444.0</td>\n",
       "      <td>Asymptotic versions for operators and operator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We will review a Lemma published by Ran Raz in...</td>\n",
       "      <td>188623.0</td>\n",
       "      <td>Some remarks on a lemma of Ran Raz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China’s growing influence in Europe has the po...</td>\n",
       "      <td>346708.0</td>\n",
       "      <td>China as a Stress Test for Europe’s Coherence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract        id  \\\n",
       "0  The goal of this note is to introduce new clas...  188444.0   \n",
       "1  We will review a Lemma published by Ran Raz in...  188623.0   \n",
       "2  China’s growing influence in Europe has the po...  346708.0   \n",
       "\n",
       "                                               title  \n",
       "0  Asymptotic versions for operators and operator...  \n",
       "1                 Some remarks on a lemma of Ran Raz  \n",
       "2      China as a Stress Test for Europe’s Coherence  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example collection\n",
    "toy_collection = ['hello hi I am a Data Science STUDENT here with Giulia and Andreas!U.S.A, United States of AMerica dixterochlomaterine hreoihso my dog ran away yesterday?! I will fly, to space tomorrow...',\n",
    "                  'space tomorrow space tomorrow if the dog ran away fly to space',\n",
    "                  ' fly to space  with my dog ran away']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-process the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-processing comprises 2 steps: \n",
    "- tokenisation, stopwords-removal, stemming (optional), lemmatizing(optional)\n",
    "- ngrams modeling (bigrams & trigrams supported)\n",
    "\n",
    "Note: the first step is only dependent on a single input document, while ngrams modeling depends on the whole collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "word_stemmer = PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "def normalisation(document, stemming = True, lemmatising = True, min_word_len = 3):\n",
    "    tokens = gensim.utils.simple_preprocess(str(document), deacc=True, max_len = sys.maxsize)\n",
    "    cleaned = [word for word in tokens if word not in stop_words]\n",
    "    if stemming:\n",
    "        cleaned = [word_stemmer.stem(word) for word in cleaned]\n",
    "    if lemmatising:\n",
    "        cleaned = [lemmatiser.lemmatize(word) for word in cleaned]\n",
    "    cleaned = [word for word in cleaned if (min_word_len<=len(word))]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "def ngram(cleaned_docs, do_trigram = True, min_count_bigram = 5, threshold_bigram = 50, min_count_trigram = 5, threshold_trigram=50):\n",
    "    #Bigrams\n",
    "    bigram = gensim.models.Phrases(cleaned_docs, min_count= min_count_bigram, threshold=threshold_bigram) \n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    output = [bigram_mod[doc] for doc in cleaned_docs]\n",
    "    #Trigrams\n",
    "    if do_trigram:\n",
    "        trigram = gensim.models.Phrases(output, min_count= min_count_trigram, threshold=threshold_trigram) \n",
    "        trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "        output = [trigram_mod[doc] for doc in output]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try out on toy collection\n",
    "toy_normalised = [normalisation(text, lemmatising = True, stemming = True, min_word_len = -1) for text in toy_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on true collection\n",
    "normalised = [normalisation(doc) for doc in collection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract topics for each document \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_top_topics(document, model, min_score=0.8):\n",
    "    \"\"\" \n",
    "    Extracting top n topics for each document. \n",
    "    Selects the n most likely topics whose p(topic|document) sum to min_score.\n",
    "    \"\"\"\n",
    "    # inserting the document in the model\n",
    "    new_doc = model.make_doc(document)\n",
    "    _,_ = model.infer(new_doc)\n",
    "    # ordering from most probable topic to least one \n",
    "    dist = new_doc.get_topic_dist()\n",
    "    indices = np.flip(np.argsort(dist))\n",
    "    score = 0\n",
    "    indices_kept = []\n",
    "    for index in indices:\n",
    "        if score > min_score: break\n",
    "        score += dist[index]\n",
    "        indices_kept.append(index)\n",
    "    return indices_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 41, 6]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying on toy collection\n",
    "get_top_topics(toy_normalised[0], model, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting topics for the original collection\n",
    "docs2topics = [get_top_topics(doc, model) for doc in normalised]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enriching original dataframe with the topics list x document \n",
    "# Note: the following command will only work if the order of documents is the same for the collection and the docs-topics list\n",
    "enriched = data\n",
    "enriched[\"topics\"] = docs2topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The goal of this note is to introduce new clas...</td>\n",
       "      <td>188444.0</td>\n",
       "      <td>Asymptotic versions for operators and operator...</td>\n",
       "      <td>[105, 15, 107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We will review a Lemma published by Ran Raz in...</td>\n",
       "      <td>188623.0</td>\n",
       "      <td>Some remarks on a lemma of Ran Raz</td>\n",
       "      <td>[105, 13, 92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China’s growing influence in Europe has the po...</td>\n",
       "      <td>346708.0</td>\n",
       "      <td>China as a Stress Test for Europe’s Coherence</td>\n",
       "      <td>[24, 15, 62, 111]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract        id  \\\n",
       "0  The goal of this note is to introduce new clas...  188444.0   \n",
       "1  We will review a Lemma published by Ran Raz in...  188623.0   \n",
       "2  China’s growing influence in Europe has the po...  346708.0   \n",
       "\n",
       "                                               title             topics  \n",
       "0  Asymptotic versions for operators and operator...     [105, 15, 107]  \n",
       "1                 Some remarks on a lemma of Ran Raz      [105, 13, 92]  \n",
       "2      China as a Stress Test for Europe’s Coherence  [24, 15, 62, 111]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploding the dataframe (one row for each document-topic pair)\n",
    "enriched=enriched.explode(\"topics\")\n",
    "enriched.columns = [\"abstract\",\"publication_id\",\"publication_title\",\"topic_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>publication_title</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The goal of this note is to introduce new clas...</td>\n",
       "      <td>188444.0</td>\n",
       "      <td>Asymptotic versions for operators and operator...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The goal of this note is to introduce new clas...</td>\n",
       "      <td>188444.0</td>\n",
       "      <td>Asymptotic versions for operators and operator...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The goal of this note is to introduce new clas...</td>\n",
       "      <td>188444.0</td>\n",
       "      <td>Asymptotic versions for operators and operator...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  publication_id  \\\n",
       "0  The goal of this note is to introduce new clas...        188444.0   \n",
       "0  The goal of this note is to introduce new clas...        188444.0   \n",
       "0  The goal of this note is to introduce new clas...        188444.0   \n",
       "\n",
       "                                   publication_title topic_id  \n",
       "0  Asymptotic versions for operators and operator...      105  \n",
       "0  Asymptotic versions for operators and operator...       15  \n",
       "0  Asymptotic versions for operators and operator...      107  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to .csv \n",
    "file_name=\"abstract+topic.csv\"\n",
    "enriched.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract words for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(topic, model, min_score=0.8):\n",
    "    \"\"\"\n",
    "    Extracting top n words for each document. \n",
    "    Selects the n most likely words whose p(word|topic) sum to min_score.\n",
    "    \"\"\"\n",
    "    dist = model.get_topic_word_dist(topic)\n",
    "    indices = np.flip(np.argsort(dist))\n",
    "    score = 0\n",
    "    word_kept = []\n",
    "    for index in indices:\n",
    "        if score > min_score: break\n",
    "        score += dist[index]\n",
    "        word_kept.append(model.used_vocabs[index])\n",
    "    return word_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tc',\n",
       " 'spectrum',\n",
       " 'peak',\n",
       " 'ce',\n",
       " 'ab',\n",
       " 'spectral',\n",
       " 'band',\n",
       " 'deriv',\n",
       " 'sa',\n",
       " 'transit',\n",
       " 'experi',\n",
       " 'signal',\n",
       " 'inclus',\n",
       " 'cen',\n",
       " 'atc',\n",
       " 'pin',\n",
       " 'nm',\n",
       " 'specif_heat']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying it out\n",
    "get_top_words(2, model, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics2words = [get_top_words(i, model, min_score=0.25) for i in range(num_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new topic dataframe\n",
    "topics_df = pd.DataFrame({\"TopicID\":range(num_topics),\"TopicWords\":topics2words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TopicID</th>\n",
       "      <th>TopicWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[flow, fluid, transport, pressur, veloc, measu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[frequenc, nois, signal, oscil, pul, modul, hz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[tc, spectrum, peak, ce, ab, spectral, band, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TopicID                                         TopicWords\n",
       "0        0  [flow, fluid, transport, pressur, veloc, measu...\n",
       "1        1  [frequenc, nois, signal, oscil, pul, modul, hz...\n",
       "2        2  [tc, spectrum, peak, ce, ab, spectral, band, d..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to .csv \n",
    "file_name=\"topics.csv\"\n",
    "topics_df.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic nodes: \n",
    "- TopicID (long)\n",
    "- Words (list(str)) \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "        #Defining the topic nodes\n",
    "        CREATE CONSTRAINT ON (c:Topic) ASSERT c.ID IS UNIQUE;\n",
    "        \n",
    "        #Loading the topic nodes \n",
    "        LOAD CSV WITH HEADERS FROM \"file:///topics.csv\" AS line\n",
    "        WITH line where line.TopicID IS NOT NULL\n",
    "        MERGE (t: Topic {ID: line.TopicID})\n",
    "        SET t.words= line.TopicWords);\n",
    "        \n",
    "        #Loading document<->topic relationships\n",
    "        LOAD CSV WITH HEADERS FROM \"file:///abstract+topic.csv\" AS line\n",
    "        MATCH (p:Publication {id:line.publication_id}),\n",
    "               (t:Topic {code:line.topic_id})\n",
    "        MERGE (p)-[:IS_ABOUT]->(t)\n",
    "        MERGE (t)-[:IS_IN]->(p);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
