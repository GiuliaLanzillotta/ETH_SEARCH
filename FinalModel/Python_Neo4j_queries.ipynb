{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Neo4j Queries\n",
    "\n",
    "**Part 1** - playground for translating ETH search input to Neo4j queries, mainly experimental\n",
    "\n",
    "**Part 2** - Neo4j commands to construct expertise score (author export on topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk import word_tokenize, RegexpTokenizer,PunktSentenceTokenizer, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(query):\n",
    "    '''\n",
    "    Performs necessary preprocessing steps to be able to match with data in Neo4j\n",
    "    '''\n",
    "    stop_words = stopwords.words('english')\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    word_stemmer = PorterStemmer()\n",
    "    count = 0\n",
    "    tokens = gensim.utils.simple_preprocess(str(query), deacc=True)\n",
    "    count += len(tokens)\n",
    "    cleaned = [word for word in tokens if word not in stop_words]\n",
    "    lemmatized = [lemmatiser.lemmatize(word_stemmer.stem(word)) for word in cleaned]\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro('machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(query):\n",
    "    tokens = gensim.utils.simple_preprocess(str(query), deacc=True)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info = pd.read_csv('graph_data_final.csv')\n",
    "print(all_info.columns)\n",
    "all_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(query_type):\n",
    "    dep_org_prof = []\n",
    "    for query in list(all_info[query_type].unique()):\n",
    "        dep_org_prof.append(normalise(query))\n",
    "    return dep_org_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_name = create_list('author')\n",
    "department = create_list('department') \n",
    "organisation = create_list('organisation')[1:] #First is nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "['andreas'] in author_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Matching - Still need to do partial Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def query_match(query):\n",
    "    norm_query = normalise(query)\n",
    "    matching_author = [all_info['author'].unique()[i] for i,v in enumerate(author_name) if set(norm_query) == set(v)]\n",
    "    #matching_org = [v for v in author_name if set(norm_query) == set(v)]\n",
    "    matching_org = [v for v in organisation if set(norm_query) == set(v)]\n",
    "    if matching_author == [] and matching_org == []:\n",
    "         # partial_matching_authors = [sublist for sublist in author_name for item in sublist if item in norm_query]\n",
    "        print('not an author')\n",
    "        print('not an organisation')\n",
    "    elif matching_author!=[]:\n",
    "        print('--------Neo4J query: Author--------')\n",
    "        print('--------Show Department--------')\n",
    "        print('MATCH (p:Person) - [r:WORKS_IN] - (d)')\n",
    "        print('WHERE p.name = '+'\\'' +' '.join(matching_author)+'\\'')\n",
    "        print('Return d')\n",
    "        print('--------Show Organisation--------')\n",
    "        print('MATCH (p:Person) - [r:BELONGS_TO] - (d)')\n",
    "        print('WHERE p.name = '+'\\'' +' '.join(matching_author)+'\\'')\n",
    "        print('Return d')\n",
    "        print('--------Show 10 most recent publications--------')\n",
    "        print('MATCH (p:Person) - [r:PUBLISHED] - (d)')\n",
    "        print('WHERE p.name = '+'\\'' +' '.join(matching_author)+'\\'')\n",
    "        print('Return d')\n",
    "        print('Limit 10')\n",
    "        print('--------Show 10 most common collaborators--------')\n",
    "        print('MATCH (p:Person)-[r1:PUBLISHED]-(pub:Publication)-[r2:PUBLISHED]-(c:Person)')\n",
    "        print('WHERE p.name = '+'\\'' +' '.join(matching_author)+'\\'')\n",
    "        print('WITH c, COUNT(pub) as cp')\n",
    "        print('RETURN c, cp')\n",
    "        print('ORDER BY cp DESCENDING')\n",
    "        print('LIMIT 10')\n",
    "        print('--------Show Expertise Areas--------')\n",
    "        print('MATCH (t:Topic) - [r:EXPERT_ON] - (p:Person)')\n",
    "        print('WHERE p.name = '+'\\'' +' '.join(matching_author)+'\\'')\n",
    "        print('RETURN r.weight, t')\n",
    "        print('ORDER BY r.weight DESC')\n",
    "    elif matching_org != []:\n",
    "        print('--------Neo4J query: Organisation--------')\n",
    "        print('MATCH (d:Department) - [:WORKS_IN] - (p:Person)')\n",
    "        print('WHERE p.name = ', matching_org)\n",
    "        print('ORDER by d.date DESC')\n",
    "        print('RETURN d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example queries\n",
    "query = ('Mohsen Ghaffari')\n",
    "query_match(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neo4J: Building the Expert score function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "            #Add weights between authors and publications\n",
    "            MATCH (p:Publication) - [r:PUBLISHED] - (a:Person)\n",
    "            SET r.weight = 1-toFloat(duration.between(p.date, date(\"2020-01-01\")).years)/toFloat(duration.between(date(\"1930-01-01\"),date(\"2020-01-01\")).years)\n",
    "            \n",
    "            #Add word count property to Topic nodes\n",
    "            MATCH (w:Word) -[r:IS_IN] -(t:Topic)\n",
    "            WITH t, count(w) as cnt\n",
    "            SET t.word_count = cnt\n",
    "            \n",
    "            #Add publication count property to Topic nodes\n",
    "            MATCH (p:Publication) -[r:IS_ABOUT] -(t:Topic)\n",
    "            WITH t, count(p) as cnt\n",
    "            SET t.pub_count = cnt\n",
    "            \n",
    "            #Create EXPERT_ON relationship between authors and topics\n",
    "            #Note: To avoid memory issues, use WHERE for selection on subsets of departments\n",
    "            #Ex: WHERE d.name IN ['Information Technology and Electrical Engineering', 'Mathematics']\n",
    "            #Engineering choice: Exponential when computing alpha\n",
    "            WITH 0.75 AS alpha_exp\n",
    "            MATCH (t:Topic)-[r1:IS_ABOUT]-(p:Publication)-[r2:PUBLISHED]-(a:Person)-[r3:WORKS_IN]-(d:Department)\n",
    "            WITH t, a, toFloat(count(p)) as cnt, alpha_exp\n",
    "            WITH t, a,\n",
    "               CASE WHEN cnt>=10.0\n",
    "                  THEN 1\n",
    "                  ELSE (cnt/10.0)^(alpha_exp)\n",
    "               END AS alpha\n",
    "            CREATE (a) - [r4:EXPERT_ON] -> (t)\n",
    "            \n",
    "            #Create score property on EXPERT_ON relationship\n",
    "            #Again, select on department to avoid memory issues\n",
    "            #Engineering choice: Exponentials for word count and publication count\n",
    "            WITH 63 AS min_pub_count, 9 AS min_word_count\n",
    "            MATCH (t:Topic)-[r1:IS_ABOUT]-(p:Publication)-[r2:PUBLISHED]-(a:Person)-[r3:WORKS_IN]-(d:Department)\n",
    "            WITH t, a, AVG(r1.weight*r2.weight)*(min_word_count/toFloat(t.word_count))^(0.75)*(min_pub_count/toFloat(t.pub_count))^(1) as s\n",
    "            MATCH (t)-[r4:EXPERT_ON]-(a)\n",
    "            SET r4.score = s*r4.alpha\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert Query Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "            #Find experts on Climate Change\n",
    "            #Find all topics that contain all search terms\n",
    "            #Aggregate expert scores, by summing over all scores between topic & author\n",
    "            #and weighting by the sum of the word probabilities in topic\n",
    "            #Engineering choice: Sum or average to aggregate word probabilites\n",
    "            WITH ['climat', 'chang']\n",
    "            as words\n",
    "            MATCH (w:Word)-[r1:IS_IN]-(t:Topic)\n",
    "            WHERE w.name in words\n",
    "            WITH t, size(words) as inputCnt, count(DISTINCT w) as cnt, SUM(r1.weight) as s\n",
    "            WHERE cnt = inputCnt\n",
    "            WITH  t, s\n",
    "            MATCH (t:Topic)-[r3:EXPERT_ON] - (p:Person)-[r2:WORKS_IN]-(d:Department)\n",
    "            WITH p, SUM(r3.score*s) as s2, d\n",
    "            RETURN p.name, s2, d.name\n",
    "            ORDER BY s2 DESC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
